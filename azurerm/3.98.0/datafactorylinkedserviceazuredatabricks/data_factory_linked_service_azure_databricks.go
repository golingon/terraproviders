// CODE GENERATED BY github.com/golingon/lingon. DO NOT EDIT.

package datafactorylinkedserviceazuredatabricks

import (
	terra "github.com/golingon/lingon/pkg/terra"
	hclwrite "github.com/hashicorp/hcl/v2/hclwrite"
)

type InstancePool struct {
	// ClusterVersion: string, required
	ClusterVersion terra.StringValue `hcl:"cluster_version,attr" validate:"required"`
	// InstancePoolId: string, required
	InstancePoolId terra.StringValue `hcl:"instance_pool_id,attr" validate:"required"`
	// MaxNumberOfWorkers: number, optional
	MaxNumberOfWorkers terra.NumberValue `hcl:"max_number_of_workers,attr"`
	// MinNumberOfWorkers: number, optional
	MinNumberOfWorkers terra.NumberValue `hcl:"min_number_of_workers,attr"`
}

type KeyVaultPassword struct {
	// LinkedServiceName: string, required
	LinkedServiceName terra.StringValue `hcl:"linked_service_name,attr" validate:"required"`
	// SecretName: string, required
	SecretName terra.StringValue `hcl:"secret_name,attr" validate:"required"`
}

type NewClusterConfig struct {
	// ClusterVersion: string, required
	ClusterVersion terra.StringValue `hcl:"cluster_version,attr" validate:"required"`
	// CustomTags: map of string, optional
	CustomTags terra.MapValue[terra.StringValue] `hcl:"custom_tags,attr"`
	// DriverNodeType: string, optional
	DriverNodeType terra.StringValue `hcl:"driver_node_type,attr"`
	// InitScripts: list of string, optional
	InitScripts terra.ListValue[terra.StringValue] `hcl:"init_scripts,attr"`
	// LogDestination: string, optional
	LogDestination terra.StringValue `hcl:"log_destination,attr"`
	// MaxNumberOfWorkers: number, optional
	MaxNumberOfWorkers terra.NumberValue `hcl:"max_number_of_workers,attr"`
	// MinNumberOfWorkers: number, optional
	MinNumberOfWorkers terra.NumberValue `hcl:"min_number_of_workers,attr"`
	// NodeType: string, required
	NodeType terra.StringValue `hcl:"node_type,attr" validate:"required"`
	// SparkConfig: map of string, optional
	SparkConfig terra.MapValue[terra.StringValue] `hcl:"spark_config,attr"`
	// SparkEnvironmentVariables: map of string, optional
	SparkEnvironmentVariables terra.MapValue[terra.StringValue] `hcl:"spark_environment_variables,attr"`
}

type Timeouts struct {
	// Create: string, optional
	Create terra.StringValue `hcl:"create,attr"`
	// Delete: string, optional
	Delete terra.StringValue `hcl:"delete,attr"`
	// Read: string, optional
	Read terra.StringValue `hcl:"read,attr"`
	// Update: string, optional
	Update terra.StringValue `hcl:"update,attr"`
}

type InstancePoolAttributes struct {
	ref terra.Reference
}

func (ip InstancePoolAttributes) InternalRef() (terra.Reference, error) {
	return ip.ref, nil
}

func (ip InstancePoolAttributes) InternalWithRef(ref terra.Reference) InstancePoolAttributes {
	return InstancePoolAttributes{ref: ref}
}

func (ip InstancePoolAttributes) InternalTokens() (hclwrite.Tokens, error) {
	return ip.ref.InternalTokens()
}

func (ip InstancePoolAttributes) ClusterVersion() terra.StringValue {
	return terra.ReferenceAsString(ip.ref.Append("cluster_version"))
}

func (ip InstancePoolAttributes) InstancePoolId() terra.StringValue {
	return terra.ReferenceAsString(ip.ref.Append("instance_pool_id"))
}

func (ip InstancePoolAttributes) MaxNumberOfWorkers() terra.NumberValue {
	return terra.ReferenceAsNumber(ip.ref.Append("max_number_of_workers"))
}

func (ip InstancePoolAttributes) MinNumberOfWorkers() terra.NumberValue {
	return terra.ReferenceAsNumber(ip.ref.Append("min_number_of_workers"))
}

type KeyVaultPasswordAttributes struct {
	ref terra.Reference
}

func (kvp KeyVaultPasswordAttributes) InternalRef() (terra.Reference, error) {
	return kvp.ref, nil
}

func (kvp KeyVaultPasswordAttributes) InternalWithRef(ref terra.Reference) KeyVaultPasswordAttributes {
	return KeyVaultPasswordAttributes{ref: ref}
}

func (kvp KeyVaultPasswordAttributes) InternalTokens() (hclwrite.Tokens, error) {
	return kvp.ref.InternalTokens()
}

func (kvp KeyVaultPasswordAttributes) LinkedServiceName() terra.StringValue {
	return terra.ReferenceAsString(kvp.ref.Append("linked_service_name"))
}

func (kvp KeyVaultPasswordAttributes) SecretName() terra.StringValue {
	return terra.ReferenceAsString(kvp.ref.Append("secret_name"))
}

type NewClusterConfigAttributes struct {
	ref terra.Reference
}

func (ncc NewClusterConfigAttributes) InternalRef() (terra.Reference, error) {
	return ncc.ref, nil
}

func (ncc NewClusterConfigAttributes) InternalWithRef(ref terra.Reference) NewClusterConfigAttributes {
	return NewClusterConfigAttributes{ref: ref}
}

func (ncc NewClusterConfigAttributes) InternalTokens() (hclwrite.Tokens, error) {
	return ncc.ref.InternalTokens()
}

func (ncc NewClusterConfigAttributes) ClusterVersion() terra.StringValue {
	return terra.ReferenceAsString(ncc.ref.Append("cluster_version"))
}

func (ncc NewClusterConfigAttributes) CustomTags() terra.MapValue[terra.StringValue] {
	return terra.ReferenceAsMap[terra.StringValue](ncc.ref.Append("custom_tags"))
}

func (ncc NewClusterConfigAttributes) DriverNodeType() terra.StringValue {
	return terra.ReferenceAsString(ncc.ref.Append("driver_node_type"))
}

func (ncc NewClusterConfigAttributes) InitScripts() terra.ListValue[terra.StringValue] {
	return terra.ReferenceAsList[terra.StringValue](ncc.ref.Append("init_scripts"))
}

func (ncc NewClusterConfigAttributes) LogDestination() terra.StringValue {
	return terra.ReferenceAsString(ncc.ref.Append("log_destination"))
}

func (ncc NewClusterConfigAttributes) MaxNumberOfWorkers() terra.NumberValue {
	return terra.ReferenceAsNumber(ncc.ref.Append("max_number_of_workers"))
}

func (ncc NewClusterConfigAttributes) MinNumberOfWorkers() terra.NumberValue {
	return terra.ReferenceAsNumber(ncc.ref.Append("min_number_of_workers"))
}

func (ncc NewClusterConfigAttributes) NodeType() terra.StringValue {
	return terra.ReferenceAsString(ncc.ref.Append("node_type"))
}

func (ncc NewClusterConfigAttributes) SparkConfig() terra.MapValue[terra.StringValue] {
	return terra.ReferenceAsMap[terra.StringValue](ncc.ref.Append("spark_config"))
}

func (ncc NewClusterConfigAttributes) SparkEnvironmentVariables() terra.MapValue[terra.StringValue] {
	return terra.ReferenceAsMap[terra.StringValue](ncc.ref.Append("spark_environment_variables"))
}

type TimeoutsAttributes struct {
	ref terra.Reference
}

func (t TimeoutsAttributes) InternalRef() (terra.Reference, error) {
	return t.ref, nil
}

func (t TimeoutsAttributes) InternalWithRef(ref terra.Reference) TimeoutsAttributes {
	return TimeoutsAttributes{ref: ref}
}

func (t TimeoutsAttributes) InternalTokens() (hclwrite.Tokens, error) {
	return t.ref.InternalTokens()
}

func (t TimeoutsAttributes) Create() terra.StringValue {
	return terra.ReferenceAsString(t.ref.Append("create"))
}

func (t TimeoutsAttributes) Delete() terra.StringValue {
	return terra.ReferenceAsString(t.ref.Append("delete"))
}

func (t TimeoutsAttributes) Read() terra.StringValue {
	return terra.ReferenceAsString(t.ref.Append("read"))
}

func (t TimeoutsAttributes) Update() terra.StringValue {
	return terra.ReferenceAsString(t.ref.Append("update"))
}

type InstancePoolState struct {
	ClusterVersion     string  `json:"cluster_version"`
	InstancePoolId     string  `json:"instance_pool_id"`
	MaxNumberOfWorkers float64 `json:"max_number_of_workers"`
	MinNumberOfWorkers float64 `json:"min_number_of_workers"`
}

type KeyVaultPasswordState struct {
	LinkedServiceName string `json:"linked_service_name"`
	SecretName        string `json:"secret_name"`
}

type NewClusterConfigState struct {
	ClusterVersion            string            `json:"cluster_version"`
	CustomTags                map[string]string `json:"custom_tags"`
	DriverNodeType            string            `json:"driver_node_type"`
	InitScripts               []string          `json:"init_scripts"`
	LogDestination            string            `json:"log_destination"`
	MaxNumberOfWorkers        float64           `json:"max_number_of_workers"`
	MinNumberOfWorkers        float64           `json:"min_number_of_workers"`
	NodeType                  string            `json:"node_type"`
	SparkConfig               map[string]string `json:"spark_config"`
	SparkEnvironmentVariables map[string]string `json:"spark_environment_variables"`
}

type TimeoutsState struct {
	Create string `json:"create"`
	Delete string `json:"delete"`
	Read   string `json:"read"`
	Update string `json:"update"`
}
